why use .ge(3) instead of >= 3?
1️⃣ Method chaining (cleaner pipelines)
df.groupby('request_id').size().ge(3).sum()
vs
(df.groupby('request_id').size() >= 3).sum()
-------------------------------------------------------------------------------------------------------
examine rows that have missing values in more than one column.
user_flags[user_flags.isna().sum(axis = 1) > 1]

Common operations using axis=1
df.sum(axis=1)          # row-wise sum
df.mean(axis=1)        # row-wise average
df.isna().any(axis=1)  # rows with at least one missing value
df.isna().all(axis=1)  # rows with all missing values
-------------------------------------------------------------------------------------------------------
df1 = orders.merge(customers, left_on = 'cust_id', right_on = 'id', how = 'left')
values = df1.groupby('cust_id')['total_order_cost'].sum().reset_index(name = 'percustspend')
df = df1.merge(values, on = 'cust_id', how = 'inner')
df['ratio'] = (df['total_order_cost'] / df['percustspend']) * 1.0
df[['first_name', 'order_details', 'ratio']]

learning -
alternate - use transform, to keep rows intact, perfect for row-level ratios

df = orders.merge(
    customers,
    left_on='cust_id',
    right_on='id',
    how='left'
)
df['ratio'] = (
    df['total_order_cost'] /
    df.groupby('cust_id')['total_order_cost'].transform('sum')
)
df[['first_name', 'order_details', 'ratio']]
-----------------------------------------------------------------------------------------------
excel_sql_inventory_data.head()
df = excel_sql_inventory_data.merge(excel_sql_transaction_data, on = 'product_id', how = 'inner')
values = df.groupby('product_id')['transaction_id'].count().reset_index(name = 'transcount')
df1 = df.merge(values, on ='product_id', how = 'inner')
df1[['product_id', 'product_name', 'transcount']].drop_duplicates().sort_values(by = 'product_id', ascending = True)
learning - 
alternate

df['transcount'] = (
    df.groupby('product_id')['transaction_id']
      .transform('count')
)   # it does same  thing , but  does not let rows collapse, so merging back is avoided

OR

counts = df.groupby('product_id')['transaction_id'].count()

df['transcount'] = df['product_id'].map(counts)
-----------------------------------------------------------------------------------------------

learning - 

cat_sales = df.groupby('category_name')['units_sold'].apply(lambda x : x.notna().any()).reset_index(name  = 'ever_sold')
# If ANY product in category has units_sold, category is sold

-----------------------------------------------------------------------------------------------
