why use .ge(3) instead of >= 3?
1️⃣ Method chaining (cleaner pipelines)
df.groupby('request_id').size().ge(3).sum()
vs
(df.groupby('request_id').size() >= 3).sum()
-------------------------------------------------------------------------------------------------------
examine rows that have missing values in more than one column.
user_flags[user_flags.isna().sum(axis = 1) > 1]

Common operations using axis=1
df.sum(axis=1)          # row-wise sum
df.mean(axis=1)        # row-wise average
df.isna().any(axis=1)  # rows with at least one missing value
df.isna().all(axis=1)  # rows with all missing values
-------------------------------------------------------------------------------------------------------
df1 = orders.merge(customers, left_on = 'cust_id', right_on = 'id', how = 'left')
values = df1.groupby('cust_id')['total_order_cost'].sum().reset_index(name = 'percustspend')
df = df1.merge(values, on = 'cust_id', how = 'inner')
df['ratio'] = (df['total_order_cost'] / df['percustspend']) * 1.0
df[['first_name', 'order_details', 'ratio']]

learning -
alternate - use transform, to keep rows intact, perfect for row-level ratios

df = orders.merge(
    customers,
    left_on='cust_id',
    right_on='id',
    how='left'
)
df['ratio'] = (
    df['total_order_cost'] /
    df.groupby('cust_id')['total_order_cost'].transform('sum')
)
df[['first_name', 'order_details', 'ratio']]
-----------------------------------------------------------------------------------------------
excel_sql_inventory_data.head()
df = excel_sql_inventory_data.merge(excel_sql_transaction_data, on = 'product_id', how = 'inner')
values = df.groupby('product_id')['transaction_id'].count().reset_index(name = 'transcount')
df1 = df.merge(values, on ='product_id', how = 'inner')
df1[['product_id', 'product_name', 'transcount']].drop_duplicates().sort_values(by = 'product_id', ascending = True)
learning - 
alternate

df['transcount'] = (
    df.groupby('product_id')['transaction_id']
      .transform('count')
)   # it does same  thing , but  does not let rows collapse, so merging back is avoided

OR

counts = df.groupby('product_id')['transaction_id'].count()

df['transcount'] = df['product_id'].map(counts)
-----------------------------------------------------------------------------------------------

learning - 

cat_sales = df.groupby('category_name')['units_sold'].apply(lambda x : x.notna().any()).reset_index(name  = 'ever_sold')
# If ANY product in category has units_sold, category is sold

-----------------------------------------------------------------------------------------------

Find the owners who have at least one facility with all 3 grades.

la_restaurant_health_inspections.head()
df = la_restaurant_health_inspections[['facility_id', 'grade', 'owner_id', 'owner_name']]
listA, listB, listC = [], [], []
grouped = df.groupby('grade')['facility_id'].apply(list)

listA = grouped.get('A', [])
listB = grouped.get('B', [])
listC = grouped.get('C', [])

common_facilities  = set(listA) & set(listB) & set(listC)
common_facilities = list(common_facilities)
common_facilities
df[df['facility_id'].isin(common_facilities)]['owner_name'].unique()

-----------------------------------------------------------------------------------------------------
Count the number of unique street names for each postal code in the business dataset. 
Use only the first word of the street name, case insensitive (e.g., "FOLSOM" and "Folsom" are the same).
If the structure is reversed (e.g., "Pier 39" and "39 Pier"),
count them as the same street.

sf_restaurant_health_violations.head()
df = sf_restaurant_health_violations
df
def canonical_street(address):
    if pd.isna(address):
        return None
    
    tokens = address.split()
    tokens = tokens[:2] if len(tokens)>= 2 else tokens
    tokens = [t.lower() for t in tokens]
    
    tokens.sort()
    return "_".join(tokens)

df['street_canonical'] = df['business_address'].apply(canonical_street)

# Step 5: drop rows with no valid address
df_valid = df.dropna(subset=['street_canonical'])  

# learning - handling multiple string operations in  a column
-----------------------------------------------------------------------------------------------------

learning - Always group in the same order as you want output
-------------------------------------------------------------------------------------------------------
Two users share a conversation if there is at least 1 message between them. Multiple messages 
between the same pair of users are
considered a single conversation.

whatsapp_messages['user_pair'] = whatsapp_messages.apply(lambda x: tuple(sorted([x['message_sender_id'], x['message_receiver_id']])), axis = 1)
----------------------------------------------------------------------------------------------------------


